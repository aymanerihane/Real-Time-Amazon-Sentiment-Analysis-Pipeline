services:

##############################
#           KAFKA
##############################
  kafka1:
    image: bitnami/kafka:latest
    container_name: kafka1
    ports:
      - "9092:9092"
      - "9093:9093"  # Controller port
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka1:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka1:9093,2@kafka2:9095
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_KRAFT_CLUSTER_ID=NTQwMzU4YzYtZGJhMS00ZGNmLTk3MmEtYTI5OGJmNWU3ZmE3
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_CFG_LOG_DIRS=/bitnami/kafka/data
      - KAFKA_CFG_CONTROLLER_QUORUM_ELECTION_TIMEOUT_MS=5000
      - KAFKA_CFG_CONTROLLER_QUORUM_FETCH_TIMEOUT_MS=5000
    volumes:
      - kafka1_data:/bitnami/kafka
    networks:
      - kafka-net
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics.sh --bootstrap-server localhost:9092 --list || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
   
    

  kafka2:
    image: bitnami/kafka:latest
    container_name: kafka2
    ports:
      - "9094:9094"
      - "9095:9095"  # Controller port
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9094,CONTROLLER://:9095
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka2:9094
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      - KAFKA_BROKER_ID=2
      - KAFKA_CFG_NODE_ID=2
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka1:9093,2@kafka2:9095
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_KRAFT_CLUSTER_ID=NTQwMzU4YzYtZGJhMS00ZGNmLTk3MmEtYTI5OGJmNWU3ZmE3
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_CFG_LOG_DIRS=/bitnami/kafka/data
      - KAFKA_CFG_CONTROLLER_QUORUM_ELECTION_TIMEOUT_MS=5000
      - KAFKA_CFG_CONTROLLER_QUORUM_FETCH_TIMEOUT_MS=5000
    volumes:
      - kafka2_data:/bitnami/kafka
    networks:
      - kafka-net
    
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics.sh --bootstrap-server localhost:9094 --list || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s


  kafka-init:
    image: bitnami/kafka:latest
    container_name: kafka-init
    depends_on:
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
    networks:
      - kafka-net
    command: >
      bash -c "
        echo 'Waiting for Kafka to be ready...' &&
        sleep 30 &&  # Increased sleep time to give Kafka more time to start
        echo 'Trying to connect to Kafka...' &&
        MAX_RETRIES=10
        RETRY_COUNT=0
        until /opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server kafka1:9092 --list; do
          echo 'Kafka not ready yet. Sleeping... (Retry $RETRY_COUNT/$MAX_RETRIES)';
          sleep 10;
          RETRY_COUNT=$((RETRY_COUNT+1))
          if [ $RETRY_COUNT -ge $MAX_RETRIES ]; then
            echo 'Max retries reached. Checking network configuration:'
            cat /etc/hosts
            ping -c 2 kafka1
            ping -c 2 kafka2
            exit 1
          fi
        done &&
        echo 'Kafka is ready. Checking topics...' &&
        # Check and create amazon-reviews-raw topic on kafka1 if it doesn't exist
        if ! /opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server kafka1:9092 --list | grep -q 'amazon-reviews-raw'; then
          echo 'Creating amazon-reviews-raw topic on kafka1...' &&
          /opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server kafka1:9092 --create --topic amazon-reviews-raw --partitions 3 --replication-factor 2 --config min.insync.replicas=1
        else
          echo 'amazon-reviews-raw topic already exists on kafka1'
        fi &&
        # Check and create sentiment-results topic on kafka2 if it doesn't exist
        if ! /opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server kafka2:9094 --list | grep -q 'sentiment-results'; then
          echo 'Creating sentiment-results topic on kafka2...' &&
          /opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server kafka2:9094 --create --topic sentiment-results --partitions 3 --replication-factor 2 --config min.insync.replicas=1
        else
          echo 'sentiment-results topic already exists on kafka2'
        fi &&
        echo 'All topics verified.'
      "
    healthcheck:
      test: ["CMD-SHELL", "/opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list | grep -E 'amazon-reviews-raw|sentiment-results' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

##############################
#          MongoDB
##############################

  # MongoDB for storing processed data
  mongodb:
    image: mongo:6.0
    hostname: mongodb
    container_name: mongodb
    ports:
      - "27019:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: example
      MONGO_INITDB_DATABASE: amazon_reviews
    volumes:
      - mongodb_data:/data/db
    networks:
      - kafka-net
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # MongoDB initialization
  mongodb-init:
    image: mongo:6.0
    depends_on:
      mongodb:
        condition: service_healthy
    restart: on-failure
    container_name: mongo-init
    entrypoint: >
      bash -c "
        echo 'Waiting for MongoDB to be ready...' &&
        until mongosh --host mongodb -u root -p example --authenticationDatabase admin --eval 'db.adminCommand(\"ping\")'; do
          echo 'MongoDB not ready yet. Sleeping...';
          sleep 5;
        done &&
        echo 'MongoDB is ready. Checking collections...' &&
        mongosh --host mongodb -u root -p example --authenticationDatabase admin --eval '
          db = db.getSiblingDB(\"amazon_reviews\");
          collections = db.getCollectionNames();
          if (!collections.includes(\"reviews\")) {
            print(\"Creating reviews collection...\");
            db.createCollection(\"reviews\");
          } else {
            print(\"reviews collection already exists\");
          }
          if (!collections.includes(\"sentiment_analysis\")) {
            print(\"Creating sentiment_analysis collection...\");
            db.createCollection(\"sentiment_analysis\");
          } else {
            print(\"sentiment_analysis collection already exists\");
          }
          if (!collections.includes(\"metrics\")) {
            print(\"Creating metrics collection...\");
            db.createCollection(\"metrics\");
          } else {
            print(\"metrics collection already exists\");
          }
          print(\"All collections verified.\");
          exit(0);
        '
      "
    networks:
      - kafka-net
    healthcheck:
      test: ["CMD", "mongosh", "--host", "mongodb", "-u", "root", "-p", "example", "--authenticationDatabase", "admin", "--eval", "db = db.getSiblingDB('amazon_reviews'); collections = db.getCollectionNames(); if (collections.includes('reviews') && collections.includes('sentiment_analysis') && collections.includes('metrics')) { exit(0); } else { exit(1); }"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

##############################
#  MODEL TRAINNER&PREDICTOR
##############################

  ml-service:
    build:
      context: ./ml-service
      dockerfile: Dockerfile
    container_name: ml-service
    restart: always
    volumes:
      - ml_data:/app/data
      - ml_data:/app/resources
      - ml_data:/app/results
    depends_on:
      - kafka1
      - kafka2
      - spark-master
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka1:9092,kafka2:9094
      - KAFKA_INPUT_TOPIC=amazon-reviews-raw
      - KAFKA_OUTPUT_TOPIC=sentiment-results
      - SPARK_MASTER_URL=spark://spark-master:7077
      - DATA_PATH=/app/data/Data.json
      - MODEL_PATH=/app/resources/sentiment_model_sklearn.pkl
      - RESULTS_PATH=/app/results
    networks:
      - kafka-net


##############################
#           SPARK
##############################


  # Spark Master
  spark-master:
    image: bitnami/spark:3.4.1
    hostname: spark-master
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - spark_data:/bitnami/spark
    networks:
      - kafka-net

  # Spark Worker
  spark-worker:
    image: bitnami/spark:3.4.1
    hostname: spark-worker
    container_name: spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - spark_data:/bitnami/spark
    networks:
      - kafka-net

##############################
#     Reviews Collector
##############################

  # Collector Service - scrapes Amazon reviews and sends to Kafka and mongodb
  collector-service:
    build:
      context: ./collector-service
      dockerfile: Dockerfile
    container_name: collector-service
    restart: unless-stopped
    depends_on:
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
      kafka-init:
        condition: service_completed_successfully
      mongodb:
        condition: service_healthy
      mongodb-init:
        condition: service_completed_successfully
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka1:9092,kafka2:9094
      - KAFKA_TOPIC=amazon-reviews-raw
      - MONGODB_URI=mongodb://root:example@mongodb:27017/amazon_reviews?authSource=admin
      - MONGODB_DATABASE=amazon_reviews
      - PYTHONUNBUFFERED=1
    volumes:
      - ./collector-service:/app
      - collector_data:/data
      - ./collector-service/data/screenshots:/data/screenshots
      - ./collector-service/data/logs:/data/logs
    networks:
      - kafka-net
    command: >
      bash -c "
        echo 'Waiting for Kafka to be ready...' &&
        MAX_RETRIES=30
        RETRY_COUNT=0
        until nc -z kafka1 9092 && nc -z kafka2 9094; do
          echo 'Kafka not ready yet. Sleeping... (Retry $RETRY_COUNT/$MAX_RETRIES)';
          sleep 5;
          RETRY_COUNT=$((RETRY_COUNT+1))
          if [ $RETRY_COUNT -ge $MAX_RETRIES ]; then
            echo 'Max retries reached. Exiting...';
            exit 1;
          fi
        done &&
        echo 'Kafka is ready. Starting collector service...' &&
        python /app/amazon_review_collector.py
      "
    healthcheck:
      test: ["CMD", "ps", "aux", "|", "grep", "python"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s

##############################
#        WEB SERVICE
##############################

  backend-service:
    build: ./backend-service
    container_name: backend-service
    ports:
      - "8006:8006"
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      mongodb:
        condition: service_healthy
      mongodb-init:
        condition: service_completed_successfully
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka1:9092,kafka2:9094
      # - KAFKA_BOOTSTRAP_SERVERS_1=kafka1:9092
      # - KAFKA_BOOTSTRAP_SERVERS_2=kafka2:9094
      - KAFKA_TOPIC_1=amazon-reviews-raw
      - KAFKA_TOPIC_2=sentiment-results
      - MONGODB_URI=mongodb://root:example@mongodb:27017/amazon_reviews?authSource=admin
      - MONGODB_DATABASE=amazon_reviews
    volumes:
      - ./backend-service:/app
      - backend_data:/data
    networks:
      - kafka-net


  # Frontend Service
  frontend-service:
    # Use a development-focused configuration
    container_name: frontend-service
    build:
      context: ./frontend-service
      dockerfile: Dockerfile.dev  # Use a dev-specific Dockerfile
    ports:
      - "5173:5173"  # Vite dev server port
    volumes:
      - ./frontend-service:/app  # Mount source code for hot reload
      - /app/node_modules  # Prevent overriding container node_modules
    environment:
      - VITE_DEV_MODE=true
      - CHOKIDAR_USEPOLLING=true  # Helps with hot reload in Docker
    networks:
      - kafka-net

  # Add this to your volumes section at the bottom
  
##############################
#         Volumes
##############################
volumes:
  frontend_data:
  kafka1_data:
  kafka2_data:
  mongodb_data:
  spark_data:
  collector_data:
  trainer_data:
  backend_data:
  ml_data:

##############################
#         NETWORKS
##############################

networks:
  kafka-net:
    driver: bridge